{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74d479f-f7f2-42a5-b2ee-968dc464fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot3 # for reading .root files\n",
    "import pandas as pd # to store data as dataframe\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
    "\n",
    "import infofile # local file containing cross-sections, sums of weights, dataset IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e89b35-e98f-4442-a71d-c33aec099906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "fraction = 0.88 # reduce this is you want the code to run quicker\n",
    "                                                                                                                                  \n",
    "#tuple_path = \"Input/4lep/\" # local \n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/4lep/\" # web address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4017bf8-40f8-43b5-81b6-0f30e0cdf821",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A','data_B','data_C','data_D'],\n",
    "    },\n",
    "\n",
    "    r'Background $Z,t\\bar{t}$' : { # Z + ttbar\n",
    "        'list' : ['Zee','Zmumu','ttbar_lep'],\n",
    "        'color' : \"#6b59d3\" # purple\n",
    "    },\n",
    "\n",
    "    r'Background $ZZ^*$' : { # ZZ\n",
    "        'list' : ['llll'],\n",
    "        'color' : \"#ff0000\" # red\n",
    "    },\n",
    "\n",
    "    r'Signal ($m_H$ = 125 GeV)' : { # H -> ZZ -> llll\n",
    "        'list' : ['ggH125_ZZ4lep','VBFH125_ZZ4lep','WH125_ZZ4lep','ZH125_ZZ4lep'],\n",
    "        'color' : \"#00cdff\" # light blue\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec6ad5-24c6-470e-88fd-a706948cf51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {} # define empty dictionary to hold dataframes\n",
    "    for s in samples: # loop over samples\n",
    "        print('Processing '+s+' samples') # print which sample\n",
    "        frames = [] # define empty list to hold data\n",
    "        for val in samples[s]['list']: # loop over each file\n",
    "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
    "            else: # MC prefix\n",
    "                prefix = \"MC/mc_\"+str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "            fileString = tuple_path+prefix+val+\".4lep.root\" # file name to open\n",
    "            temp = read_file(fileString,val) # call the function read_file defined below\n",
    "            frames.append(temp) # append dataframe returned from read_file to list of dataframes\n",
    "        data[s] = pd.concat(frames) # dictionary entry is concatenated dataframes\n",
    "    \n",
    "    return data # return dictionary of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246db627-94ae-4c2d-a614-9fc3cde3efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(xsec_weight, mcWeight, scaleFactor_PILEUP,\n",
    "                scaleFactor_ELE, scaleFactor_MUON, \n",
    "                scaleFactor_LepTRIGGER ):\n",
    "    return xsec_weight*mcWeight*scaleFactor_PILEUP*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_LepTRIGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc079d1-df2c-42ef-bd91-e98ef27ad125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xsec_weight(sample):\n",
    "    info = infofile.infos[sample] # open infofile\n",
    "    xsec_weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    return xsec_weight # return cross-section weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9ab79-9d81-4d20-a10d-1f6e499dbf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mllll(lep_pt,lep_eta,lep_phi,lep_E):\n",
    "    # first lepton is [0], 2nd lepton is [1] etc\n",
    "    px_0 = lep_pt[0]*math.cos(lep_phi[0]) # x-component of lep[0] momentum\n",
    "    py_0 = lep_pt[0]*math.sin(lep_phi[0]) # y-component of lep[0] momentum\n",
    "    pz_0 = lep_pt[0]*math.sinh(lep_eta[0]) # z-component of lep[0] momentum\n",
    "    px_1 = lep_pt[1]*math.cos(lep_phi[1]) # x-component of lep[1] momentum\n",
    "    py_1 = lep_pt[1]*math.sin(lep_phi[1]) # y-component of lep[1] momentum\n",
    "    pz_1 = lep_pt[1]*math.sinh(lep_eta[1]) # z-component of lep[1] momentum\n",
    "    px_2 = lep_pt[2]*math.cos(lep_phi[2]) # x-component of lep[2] momentum\n",
    "    py_2 = lep_pt[2]*math.sin(lep_phi[2]) # y-component of lep[2] momentum\n",
    "    pz_2 = lep_pt[2]*math.sinh(lep_eta[2]) # z-component of lep[3] momentum\n",
    "    px_3 = lep_pt[3]*math.cos(lep_phi[3]) # x-component of lep[3] momentum\n",
    "    py_3 = lep_pt[3]*math.sin(lep_phi[3]) # y-component of lep[3] momentum\n",
    "    pz_3 = lep_pt[3]*math.sinh(lep_eta[3]) # z-component of lep[3] momentum\n",
    "    sumpx = px_0 + px_1 + px_2 + px_3 # x-component of 4-lepton momentum\n",
    "    sumpy = py_0 + py_1 + py_2 + py_3 # y-component of 4-lepton momentum\n",
    "    sumpz = pz_0 + pz_1 + pz_2 + pz_3 # z-component of 4-lepton momentum\n",
    "    sumE = lep_E[0] + lep_E[1] + lep_E[2] + lep_E[3] # energy of 4-lepton system\n",
    "    return math.sqrt(sumE**2 - sumpx**2 - sumpy**2 - sumpz**2)/1000 #/1000 to go from MeV to GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d76f1-913b-4047-8139-5257de5a748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut on lepton charge\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_charge(lep_charge):\n",
    "# throw away when sum of lepton charges is not equal to 0\n",
    "# first lepton is [0], 2nd lepton is [1] etc\n",
    "    return lep_charge[0] + lep_charge[1] + lep_charge[2] + lep_charge[3] != 0\n",
    "\n",
    "# cut on lepton type\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_type(lep_type):\n",
    "# for an electron lep_type is 11\n",
    "# for a muon lep_type is 13\n",
    "# throw away when none of eeee, mumumumu, eemumu\n",
    "    sum_lep_type = lep_type[0] + lep_type[1] + lep_type[2] + lep_type[3]\n",
    "    return (sum_lep_type != 44) and (sum_lep_type != 48) and (sum_lep_type != 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc617f-7d67-490a-aaed-7c523499a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
    "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
    "    tree = uproot3.open(path)[\"mini\"] # open the tree called mini\n",
    "    numevents = uproot3.numentries(path, \"mini\") # number of events\n",
    "    if 'data' not in sample: xsec_weight = get_xsec_weight(sample) # get cross-section weight\n",
    "    for data in tree.iterate(['lep_pt','lep_eta','lep_phi',\n",
    "                              'lep_E','lep_charge','lep_type', \n",
    "                              # add more variables here if you make cuts on them \n",
    "                              'mcWeight','scaleFactor_PILEUP',\n",
    "                              'scaleFactor_ELE','scaleFactor_MUON',\n",
    "                              'scaleFactor_LepTRIGGER'], # variables to calculate Monte Carlo weight\n",
    "                             outputtype=pd.DataFrame, # choose output type as pandas DataFrame\n",
    "                             entrystop=numevents*fraction): # process up to numevents*fraction\n",
    "\n",
    "        nIn = len(data.index) # number of events in this batch\n",
    "\n",
    "        if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
    "            # multiply all Monte Carlo weights and scale factors together to give total weight\n",
    "            data['totalWeight'] = np.vectorize(calc_weight)(xsec_weight,\n",
    "                                                            data.mcWeight,\n",
    "                                                            data.scaleFactor_PILEUP,\n",
    "                                                            data.scaleFactor_ELE,\n",
    "                                                            data.scaleFactor_MUON,\n",
    "                                                            data.scaleFactor_LepTRIGGER)\n",
    "\n",
    "        # cut on lepton charge using the function cut_lep_charge defined above\n",
    "        fail = data[ np.vectorize(cut_lep_charge)(data.lep_charge) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # cut on lepton type using the function cut_lep_type defined above\n",
    "        fail = data[ np.vectorize(cut_lep_type)(data.lep_type) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # calculation of 4-lepton invariant mass using the function calc_mllll defined above\n",
    "        data['mllll'] = np.vectorize(calc_mllll)(data.lep_pt,data.lep_eta,data.lep_phi,data.lep_E)\n",
    "\n",
    "        # dataframe contents can be printed at any stage like this\n",
    "        #print(data)\n",
    "\n",
    "        # dataframe column can be printed at any stage like this\n",
    "        #print(data['lep_pt'])\n",
    "\n",
    "        # multiple dataframe columns can be printed at any stage like this\n",
    "        #print(data[['lep_pt','lep_eta']])\n",
    "\n",
    "        nOut = len(data.index) # number of events passing cuts in this batch\n",
    "        data_all = data_all.append(data) # append dataframe from this batch to the dataframe for the whole sample\n",
    "        elapsed = time.time() - start # time taken to process\n",
    "        print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "    \n",
    "    return data_all # return dataframe containing events passing all cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6622d9-d5df-4e21-bbb6-b24a62905471",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19afab-6af0-4e7f-b625-ae9257b7effa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "\n",
    "    xmin = 80 # GeV\n",
    "    xmax = 250 # GeV\n",
    "    step_size = 5 # GeV\n",
    "\n",
    "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
    "                     stop=xmax+step_size, # The interval doesn't include this value\n",
    "                     step=step_size ) # Spacing between values\n",
    "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                            step=step_size ) # Spacing between values\n",
    "\n",
    "    data_x,_ = np.histogram(data['data']['mllll'], \n",
    "                            bins=bin_edges ) # histogram the data\n",
    "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "    signal_x = data[r'Signal ($m_H$ = 125 GeV)']['mllll'] # histogram the signal\n",
    "    signal_weights = data[r'Signal ($m_H$ = 125 GeV)'].totalWeight # get the weights of the signal events\n",
    "    signal_color = samples[r'Signal ($m_H$ = 125 GeV)']['color'] # get the colour for the signal bar\n",
    "\n",
    "    mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
    "    mc_weights = [] # define list to hold the Monte Carlo weights\n",
    "    mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
    "    mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
    "\n",
    "    for s in samples: # loop over samples\n",
    "        if s not in ['data', r'Signal ($m_H$ = 125 GeV)']: # if not data nor signal\n",
    "            mc_x.append( data[s]['mllll'] ) # append to the list of Monte Carlo histogram entries\n",
    "            mc_weights.append( data[s].totalWeight ) # append to the list of Monte Carlo weights\n",
    "            mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
    "            mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
    "    \n",
    "\n",
    "\n",
    "    # *************\n",
    "    # Main plot \n",
    "    # *************\n",
    "    main_axes = plt.gca() # get current axes\n",
    "    \n",
    "    # plot the data points\n",
    "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
    "                       fmt='ko', # 'k' means black and 'o' is for circles \n",
    "                       label='Data') \n",
    "    \n",
    "    # plot the Monte Carlo bars\n",
    "    mc_heights = main_axes.hist(mc_x, bins=bin_edges, \n",
    "                                weights=mc_weights, stacked=True, \n",
    "                                color=mc_colors, label=mc_labels )\n",
    "    \n",
    "    mc_x_tot = mc_heights[0][-1] # stacked background MC y-axis value\n",
    "    mc_x_err = np.sqrt( mc_x_tot ) # statistical error on the MC bars\n",
    "    \n",
    "    # plot the signal bar\n",
    "    main_axes.hist(signal_x, bins=bin_edges, bottom=mc_x_tot, \n",
    "                   weights=signal_weights, color=signal_color,\n",
    "                   label=r'Signal ($m_H$ = 125 GeV)')\n",
    "    \n",
    "    # plot the statistical uncertainty\n",
    "    main_axes.bar(bin_centres, # x\n",
    "                  2*mc_x_err, # heights\n",
    "                  alpha=0.5, # half transparency\n",
    "                  bottom=mc_x_tot-mc_x_err, color='none', \n",
    "                  hatch=\"////\", width=step_size, label='Stat. Unc.' )\n",
    "\n",
    "    # set the x-limit of the main axes\n",
    "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
    "    \n",
    "    # separation of x axis minor ticks\n",
    "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # set the axis tick parameters for the main axes\n",
    "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                          direction='in', # Put ticks inside and outside the axes\n",
    "                          top=True, # draw ticks on the top axis\n",
    "                          right=True ) # draw ticks on right axis\n",
    "    \n",
    "    # x-axis label\n",
    "    main_axes.set_xlabel(r'4-lepton invariant mass $\\mathrm{m_{4l}}$ [GeV]',\n",
    "                        fontsize=13, x=1, horizontalalignment='right' )\n",
    "    \n",
    "    # write y-axis label for main axes\n",
    "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV',\n",
    "                         y=1, horizontalalignment='right') \n",
    "    \n",
    "    # set y-axis limits for main axes\n",
    "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.6 )\n",
    "    \n",
    "    # add minor ticks on y-axis for main axes\n",
    "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "\n",
    "    # Add text 'ATLAS Open Data' on plot\n",
    "    plt.text(0.05, # x\n",
    "             0.93, # y\n",
    "             'ATLAS Open Data', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=13 ) \n",
    "    \n",
    "    # Add text 'for education' on plot\n",
    "    plt.text(0.05, # x\n",
    "             0.88, # y\n",
    "             'for education', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             style='italic',\n",
    "             fontsize=8 ) \n",
    "    \n",
    "    # Add energy and luminosity\n",
    "    lumi_used = str(lumi*fraction) # luminosity to write on the plot\n",
    "    plt.text(0.05, # x\n",
    "             0.82, # y\n",
    "             '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "    \n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.05, # x\n",
    "             0.76, # y\n",
    "             r'$H \\rightarrow ZZ^* \\rightarrow 4\\ell$', # text \n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "    # draw the legend\n",
    "    main_axes.legend( frameon=False ) # no box around the legend\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8cc95-d4ff-476b-a4a5-533a1209ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
